[toc]

# 1 统计学基础
## 1.1 统计学
- 什么是**统计学**？统计学是寻找更好的数据应用方法的学科。
- 为了整理、归纳现有数据而产生的统计学分支，叫作**描述统计**。
- 为了估计不在我们手中的未知数据而产生的统计学分支叫作**统计推断**。
- **使用现有数据能推断未知数据**——这可以说是学习统计学给我们带来的最大好处。
- **样本**是指现有数据。
- **总体**是指既包含现有数据也包含未知数据的全部数据。
- **只使用样本这一部分数据来讨论总体这一全部数据**就是统计推断的目标。

## 1.2 获取样本的过程
- 根据随机法则变化的量叫作**随机变量**。
- 由随机变量得来的具体数值叫作**样本值**。
- 从总体中获取样本叫作**抽样**。
- 随机选择总体中各个元素的方法叫作**简单随机抽样（随机抽样）**。
- 样本的大小或现有数据的个数叫作**样本容量**。
- 调查完整的总体叫作**普查**。
- 只调查总体的一部分叫作**抽样调查**。

## 1.3 抽样过程的抽象描述
- **概率**使用它的英文$probability$的首字母$P$来表示。获得某个数据的概率记为$P(数据)$。
- **概率分布（分布）**表示随机变量及其概率之间的关系。
- 当某数据和某种概率分布相符时，就叫作**服从概率分布**。
- 总体服从的概率分布叫作**总体分布**。
- 像投掷骰子的实验这种结果范围无穷大的总体叫作**无限总体**。
- 使用瓮中取球的实验来描述多种现象的模型叫作**瓮模型**。

## 1.4 描述统计基础
- “定量”的意思就是**数值之间的差距所代表的意义是等价的**。
- 能够定量表示的数据叫作**定量变量（数值变量）**。
- 定量变量又分为两种。1条、2条这种只取整数的数据叫作**离散变量**。2.3cm、4.25cm这种会取到小数点之后的值且变化连续的数据叫作**连续变量**。
- 不能定量表示的数据叫作**分类变量**。
- 如果把鱼分为青鳉和鲤鱼2种，则“青鳉”等种类名称就是分类变量，这也叫作**名义尺度**。有的分类变量叫作**顺序尺度**，比如，把鱼按大、中、小进行区分， 像这种有顺序的分类就是顺序尺度。
- 在定量变量中，我们经常会看到数值被分成几个范围，这些范围就叫作**组**。
- 代表组的值叫作**组中值**，取组的最大值和最小值之间的中间数值。
- **频数**就是某个数据出现的次数。
- **频数分布**是每个组中数据的频数的排列。
- 频数占总数的比例叫作**频率**。
- 把组按从小到大的顺序排列，将频数相加，得到的和叫作**累积频数**。
- 按同样方法得到的频率的和叫作**累积频率**。
- 表示频数分布的图叫作**直方图**。在直方图中，横轴是组，纵轴是频数。
- 用于统计数据的值叫作**统计量**。
- 最常用的统计量是**均值**。
- 需要注意的是，均值被用作代表已知数据（样本）的值，即**代表值**。
- 在统计学中，均值经常被称为期望值。我们可以把期望值理解为能够用于未知数据的均值。
- **方差**用来表示数据与均值（期望值）之间相差多少。

## 1.5 总体分布的推断
- 统计学中会通过**做假设**来简化计算。
- 在统计学中也会为总体分布做假设，**正态分布**就是其中一种，既容易计算又符合数据。

## 1.6 概率质量函数与概率密度函数
- 在将数据作为参数时，所得函数值是概率的函数叫作**概率质量函数**。
- 离散变量可以直接计算概率，而连续变量不能直接计算概率，于是人们就用**概率密度**来代替概率。我们可以 把概率密度看作用于连续变量的类似于概率的概念。
- 可以认为**积分是加法的扩展**。
- 在将数据作为参数时，所得函数值是概率密度的函数叫作**概率密度函数**。
- **参数**是用于定义概率分布的值。
- 正态分布有两个参数，分别是均值（期望值）$\mu$和方差$\sigma ^{2}$。若将随机变量记为$x$，则正态分布的概率密度函数就记为$\mathcal{N}(x)$。通过计算$\mathcal{N}(x)$，可以求得随机变量对应的概率密度。有时也将正态分布的概率密度函数记为$\mathcal{N}(x|\mu , \sigma ^{2})$，以明确地表示参数。
- **估计参数最直接的思路就是把样本的统计量看作总体分布的参数**。
- 但是样本的统计量和参数之间普遍存在差别，我们必须认识到估计出来的参数存在**估计误差**。
- 在进行参数估计时，如果要考虑估计误差，可以使用**区间估计**等方法。
- 在存在估计误差的情况下依然要证明某个想法时，可以使用**假设检验**。

## 1.7 统计量的计算
- 样本的均值$\mu$可通过该式求出：$\mu = \frac{1}{N}\sum_{i=1}^{N}x_{i}$，准确来说，这个均值叫作**算术平均值**。
- 离散变量的期望值$\mu$可以通过求“取值的概率$\times$取到的值”的总和计算出来：$\mu = \sum_{i=1}^{N}P(x_{i})\cdot x_{i}$。
- 总体的均值叫作**总体均值**。样本的均值叫作**样本均值**。总体均值与样本均值经常存在差距，但不会偏离。
- 方差用来表示数据与均值（期望值）之间相差多少，由该式求得：$\sigma ^{2} = \frac{1}{N}\sum_{i=1}^{N}(x_{i} - \mu)^{2}$。其中，$x_{i} - \mu$叫作**偏差**。各个偏差的平方的总和，即$\sum (x_{i} - \mu)^{2}$，叫作**偏差平方和**。
- 使用概率$P(x_{i})$，可以将方差表示为：$\sigma ^{2} = \sum_{i=1}^{N}P(x_{i})\cdot (x_{i} - \mu)^{2}$。数据和期望值之间相差越大，$(x_{i} - \mu)^{2}$的值越大。$(x_{i} - \mu)^{2}$可用来表示数据与期望值之间的距离。因此，方差也就是数据与期望值之间的距离的期望值。准确来说，此处的方差叫作**样本方差**。
- 样本方差和总体方差之间存在偏离，前者比后者偏小。**无偏方差**就是为了修正这个偏离而出现的。通过该式计算无偏方差：$\sigma ^{2} = \frac{1}{N - 1}\sum_{i=1}^{N}(x_{i} - \mu)^{2}$。
- 标准差通过对方差取平方根而得出：$\sigma = \sqrt{\sigma ^{2}} = \sqrt{\frac{1}{N - 1}\sum_{i=1}^{N}(x_{i} - \mu)^{2}}$。这里的方差一般使用无偏方差。

## 1.8 概率论基础
- **集合**是由客观标准定义的事物一起形成的总体。
- 设有集合$A$，某个事物$a$是$A$的**元素**，则记作$a\in A$，读作$a$**属于**$A$。
- 设有两个集合$A$、$B$。如果当$a\in A$时，$a\in B$，则称$A$是$B$的**子集**，记作$A\subset B$。
- 在比较集合时，人们经常使用**维恩图**。
- 对于$A$、$B$两个集合，**交集**$A\cap B$的定义为：$A\cap B = \{a; a\in A 且 a\in B\}$。
- 对于$A$、$B$两个集合，**并集**$A\cup B$的定义为：$A\cup B = \{a; a\in A 或 a\in B\}$。
- 对于$A$、$B$两个集合，**差集**$A - B$的定义为：$A - B = \{a; a\in A 且 a\notin B\}$。
- 不含任何元素的集合叫作**空集**，记作$\emptyset$。
- 设有集合$S$，当所研究的问题只考虑$S$的子集时，称$S$为**全集**。
- 已知全集$S$，关于$S$的子集$A$有如下关系成立，则称集合$A^{c}$为$A$的**补集**。
- 可能发生的实验结果称为**样本点（$\omega$）**，样本点的总体的集合称为**样本空间（$\Omega$）**。
- 样本空间的子集叫作**事件**。与集合一样，事件也有**并事件**与**交事件**的定义。
- 只由一个样本点组成且不可再分解的事件叫作**基本事件**。含有多个样本点且可以分解为多个基本事件的事件叫作**复合事件**。与空集类似，不含任何样本点的事件叫作**空事件**。
- 当$A\cap B = \emptyset$时，或者当事件之间没有重叠时，称事件$A$和$B$是**互斥事件**。
- **概率的加法公式**是，如果$A$、$B$是互斥事件，则满足：$P(A\cup B) = P(A) + P(B)$。去掉互斥的条件，将概率的加法公式一般化：$P(A\cup B) = P(A) + P(B) - P(A\cap B)$。
- 以发生事件$B$为前提条件，事件$A$发生的概率叫作**条件概率**，记作$P(A|B)$，定义为：$P(A|B) = \frac{P(A\cap B)}{P(B)}$。
- 将条件概率的公式进行变形，可得到：$P(A\cap B) = P(B)\cdot P(A|B)$。该式称为**概率的乘法公式**。
- 当$P(A\cap B) = P(A)\cdot P(B)$成立时，称事件$A$、$B$相独立。变形后就是$P(A|B) = P(A)$。

## 1.9 随机变量与概率分布
- 离散型数据可以通过求概率的总和来得到各种事件的概率，而连续型数据则要通过求概率密度的积分来得到事件的概率。二者的方法是互相对应的。
- 积分就是曲线下方的面积大小。当$n\rightarrow \infty$时，即**当区间分成无穷多个时，面积之和就叫作积分**，表示为$\lim_{n\rightarrow \infty}[\sum_{i=1}^{n}f(x_{i})\times \Delta x] = \int_{a}^{b}f(x)dx$。
- 正态分布的概率密度函数为：$\mathcal{N}(x|\mu , \sigma ^{2}) = \frac{1}{\sqrt{2\pi \sigma ^{2}}}e^{[-\frac{(x - \mu)^{2}}{2\sigma ^2}]}$。
- **独立同分布**即随机变量服从同一分布且相互独立。

# 3 使用$Python$进行数据分析
## 3.1 使用$Python$进行描述统计：单变量
- **标准化**就是把均值转化为0，把标准差（方差）转化为1。要使得均值为0，只需用所有样本减去均值即可。同样，要使得数据的标准差（方差）为1，只需用所有样本除以标 准差即可。
- 把数据按升序排列，位置在最中间的数就是**中位数**。
- 均值易受**极端值**的影响，而中位数不易受极端值的影响。因此，**中位数对于极端值更有稳健性**。
- 把数据按升序排列，处在25%和75%位置的数就是**四分位数**。

## 3.2 使用$Python$进行描述统计：多变量
- 研究两个连续变量之间的关系时使用的统计量叫作**协方差**。变量$x$、$y$的协方差$Cov(x, y)$的计算公式为：$Cov(x, y) = \frac{1}{N}\sum_{i=1}^{N}(x_{i} - \mu _{x})(y_{i} - \mu _{y})$。其中，$\mu _{x}$、$\mu _{y}$分别是变量$x$、$y$的均值，$N$是样本容量。
- 和方差一样，协方差的公式中也可以使用$N - 1$作为分母：$Cov(x, y) = \frac{1}{N - 1}\sum_{i=1}^{N}(x_{i} - \mu _{x})(y_{i} - \mu _{y})$。
- 把多个变量的方差和协方差放在一起形成的矩阵，叫作**协方差矩阵**。变量$x$、$y$的协方差矩阵为：$Cov(x, y) = \left[ \matrix{\sigma _{x}^{2} & Cov(x, y)\\ Cov(x, y) & \sigma _{y}^{2}} \right]$。其中，$\sigma _{x}^{2}$、$\sigma _{y}^{2}$分别是$x$、$y$的方差。
- 对于变量$x$、$y$，该式计算所得的$\rho _{xy}$叫作**皮尔逊积矩相关系数（相关系数）**：$\rho _{xy} = \frac{Cov(x, y)}{\sqrt{\sigma _{x}^{2}\sigma _{y}^{2}}}$。该式也可以看作将协方差标准化成最大值为1、最小值为-1而得出的。
- 把多个变量的相关系数放在一起得到的矩阵，叫作**相关矩阵**。变量$x$、$y$的相关矩阵为：$Cov(x, y) = \left[ \matrix{1 & \rho _{xy}\\ \rho _{xy} & 1} \right]$。

## 3.4 用$Python$模拟抽样
- 随机得到的数叫作**随机数**。有些领域会将其看作随机变量。
- 把抽出的样本放回总体再重新抽样叫作**放回抽样**，抽出的样本不放回总体的抽样叫作**不放回抽样**。

## 3.5 样本统计量的性质
- 试验可以在完全相同的条件下进行多次，这叫作**重复试验**。
- 在能够重复试验的前提下重复进行试验的次数叫作**试验次数**。
- **样本分布**是样本的统计量所服从的概率分布。
- 样本均值的标准差的理论值叫**标准误差**，计算公式：$标准误差 = \frac{\sigma }{\sqrt{N}}$，其中，$\sigma$是标准差，$N$是样本容量。样本容量越大，标准误差就越小。
- 估计量的期望值相当于真正的参数的特性叫作**无偏性**。
- 样本容量越大，估计量越接近真正的参数的特性称为**一致性**。
- 所谓**大数定律**，就是样本容量越大，样本均值越接近总体均值。
- 对于任意总体分布，样本容量越大，随机变量的和的分布越接近正态分布，这就是**中心极限定理**。

## 3.6 正态分布及其应用
- 在该式中：$F(X) = P(X\leq x)$，对于随机变量$X$，当$x$为实数时，$F(X)$叫作**累积分布函数（分布函数）**。简单来说，累积分布函数可以计算随机变量小于等于某个值的概率。
- 数据小于等于某个值的概率叫作**左侧概率**。借助累积分布函数可以得到左侧概率。
- 与上述概念相反，能得到某个概率的那个值叫作**百分位数**，也叫左侧百分位数。
- 均值为0、方差（或标准差）为1的正态分布叫作标准正态分布，即$\mathcal{N}(x|0, 1)$。
- 统计量$t$值的计算方法为：$t = \frac{\hat{\mu} - \mu}{\hat{\sigma}/\sqrt{N}}$。其中，$\hat{\mu}$为样本均值，$\mu$为总体均值，$\hat{\sigma}$为实际样本的无偏标准差（无偏方差的平方根），$N$为样本容量。文字描述为：$t值 = \frac{样本均值 - 总体均值}{标准误差}$。
- $t$值的公式与标准化公式类似。标准化就是把均值转化为0，把方差转化为1。$t$值可以理解为对样本均值进行标准化，然而这个计算的除数不是标准误差的理论值，它来自实际样本，不能把方差转化为1。

## 3.7 参数估计
## 3.8 假设检验
## 3.9 均值差的检验
## 3.10 列联表检验
## 3.11 检验结果的解读

# 4 统计模型基础
## 4.1 统计模型
## 4.2 建模方法
## 4.3 数据表示与模型名称
## 4.4 参数估计：最大似然估计
## 4.5 参数估计：最小化损失
## 4.6 预测精度的评估与变量选择

# 5 正态线性模型
## 5.1 含有单个连续型解释变量的模型（一元回归）
## 5.2 方差分析
## 5.3 含有多个解释变量的模型

# 6 广义线性模型
## 6.1 各种概率分布
## 6.2 广义线性模型基础
## 6.3 $logistic$回归
## 6.4 广义线性模型的评估
## 6.5 泊松回归

# 7 统计学与机器学习
## 7.1 机器学习基础
## 7.2 正则化、$Ridge$回归与$Lasso$回归
## 7.3 $Python$中的$Ridge$回归与$Lasso$回归
## 7.4 线性模型与神经网络
## 7.5 扩展内容