[toc]

# 1 统计学基础
## 1.1 统计学
- 什么是**统计学**？统计学是寻找更好的数据应用方法的学科。
- 为了整理、归纳现有数据而产生的统计学分支，叫作**描述统计**。
- 为了估计不在我们手中的未知数据而产生的统计学分支叫作**统计推断**。
- **使用现有数据能推断未知数据**——这可以说是学习统计学给我们带来的最大好处。
- **样本**是指现有数据。
- **总体**是指既包含现有数据也包含未知数据的全部数据。
- **只使用样本这一部分数据来讨论总体这一全部数据**就是统计推断的目标。

## 1.2 获取样本的过程
- 根据随机法则变化的量叫作**随机变量**。
- 由随机变量得来的具体数值叫作**样本值**。
- 从总体中获取样本叫作**抽样**。
- 随机选择总体中各个元素的方法叫作**简单随机抽样（随机抽样）**。
- 样本的大小或现有数据的个数叫作**样本容量**。
- 调查完整的总体叫作**普查**。
- 只调查总体的一部分叫作**抽样调查**。

## 1.3 抽样过程的抽象描述
- **概率**使用它的英文$probability$的首字母$P$来表示。获得某个数据的概率记为$P(数据)$。
- **概率分布（分布）**表示随机变量及其概率之间的关系。
- 当某数据和某种概率分布相符时，就叫作**服从概率分布**。
- 总体服从的概率分布叫作**总体分布**。
- 像投掷骰子的实验这种结果范围无穷大的总体叫作**无限总体**。
- 使用瓮中取球的实验来描述多种现象的模型叫作**瓮模型**。

## 1.4 描述统计基础
- “定量”的意思就是**数值之间的差距所代表的意义是等价的**。
- 能够定量表示的数据叫作**定量变量（数值变量）**。
- 定量变量又分为两种。1条、2条这种只取整数的数据叫作**离散变量**。2.3cm、4.25cm这种会取到小数点之后的值且变化连续的数据叫作**连续变量**。
- 不能定量表示的数据叫作**分类变量**。
- 如果把鱼分为青鳉和鲤鱼2种，则“青鳉”等种类名称就是分类变量，这也叫作**名义尺度**。有的分类变量叫作**顺序尺度**，比如，把鱼按大、中、小进行区分， 像这种有顺序的分类就是顺序尺度。
- 在定量变量中，我们经常会看到数值被分成几个范围，这些范围就叫作**组**。
- 代表组的值叫作**组中值**，取组的最大值和最小值之间的中间数值。
- **频数**就是某个数据出现的次数。
- **频数分布**是每个组中数据的频数的排列。
- 频数占总数的比例叫作**频率**。
- 把组按从小到大的顺序排列，将频数相加，得到的和叫作**累积频数**。
- 按同样方法得到的频率的和叫作**累积频率**。
- 表示频数分布的图叫作**直方图**。在直方图中，横轴是组，纵轴是频数。
- 用于统计数据的值叫作**统计量**。
- 最常用的统计量是**均值**。
- 需要注意的是，均值被用作代表已知数据（样本）的值，即**代表值**。
- 在统计学中，均值经常被称为期望值。我们可以把期望值理解为能够用于未知数据的均值。
- **方差**用来表示数据与均值（期望值）之间相差多少。

## 1.5 总体分布的推断
- 统计学中会通过**做假设**来简化计算。
- 在统计学中也会为总体分布做假设，**正态分布**就是其中一种，既容易计算又符合数据。

## 1.6 概率质量函数与概率密度函数
- 在将数据作为参数时，所得函数值是概率的函数叫作**概率质量函数**。
- 离散变量可以直接计算概率，而连续变量不能直接计算概率，于是人们就用**概率密度**来代替概率。我们可以 把概率密度看作用于连续变量的类似于概率的概念。
- 可以认为**积分是加法的扩展**。
- 在将数据作为参数时，所得函数值是概率密度的函数叫作**概率密度函数**。
- **参数**是用于定义概率分布的值。
- 正态分布有两个参数，分别是均值（期望值）$\mu$和方差$\sigma ^{2}$。若将随机变量记为$x$，则正态分布的概率密度函数就记为$\mathcal{N}(x)$。通过计算$\mathcal{N}(x)$，可以求得随机变量对应的概率密度。有时也将正态分布的概率密度函数记为$\mathcal{N}(x|\mu , \sigma ^{2})$，以明确地表示参数。
- **估计参数最直接的思路就是把样本的统计量看作总体分布的参数**。
- 但是样本的统计量和参数之间普遍存在差别，我们必须认识到估计出来的参数存在**估计误差**。
- 在进行参数估计时，如果要考虑估计误差，可以使用**区间估计**等方法。
- 在存在估计误差的情况下依然要证明某个想法时，可以使用**假设检验**。

## 1.7 统计量的计算
- 样本的均值$\mu$可通过该式求出：$\mu = \frac{1}{N}\sum_{i=1}^{N}x_{i}$，准确来说，这个均值叫作**算术平均值**。
- 离散变量的期望值$\mu$可以通过求“取值的概率$\times$取到的值”的总和计算出来：$\mu = \sum_{i=1}^{N}P(x_{i})\cdot x_{i}$。
- 总体的均值叫作**总体均值**。样本的均值叫作**样本均值**。总体均值与样本均值经常存在差距，但不会偏离。
- 方差用来表示数据与均值（期望值）之间相差多少，由该式求得：$\sigma ^{2} = \frac{1}{N}\sum_{i=1}^{N}(x_{i} - \mu)^{2}$。其中，$x_{i} - \mu$叫作**偏差**。各个偏差的平方的总和，即$\sum (x_{i} - \mu)^{2}$，叫作**偏差平方和**。
- 使用概率$P(x_{i})$，可以将方差表示为：$\sigma ^{2} = \sum_{i=1}^{N}P(x_{i})\cdot (x_{i} - \mu)^{2}$。数据和期望值之间相差越大，$(x_{i} - \mu)^{2}$的值越大。$(x_{i} - \mu)^{2}$可用来表示数据与期望值之间的距离。因此，方差也就是数据与期望值之间的距离的期望值。准确来说，此处的方差叫作**样本方差**。
- 样本方差和总体方差之间存在偏离，前者比后者偏小。**无偏方差**就是为了修正这个偏离而出现的。通过该式计算无偏方差：$\sigma ^{2} = \frac{1}{N - 1}\sum_{i=1}^{N}(x_{i} - \mu)^{2}$。
- 标准差通过对方差取平方根而得出：$\sigma = \sqrt{\sigma ^{2}} = \sqrt{\frac{1}{N - 1}\sum_{i=1}^{N}(x_{i} - \mu)^{2}}$。这里的方差一般使用无偏方差。

## 1.8 概率论基础
- **集合**是由客观标准定义的事物一起形成的总体。
- 设有集合$A$，某个事物$a$是$A$的**元素**，则记作$a\in A$，读作$a$**属于**$A$。
- 设有两个集合$A$、$B$。如果当$a\in A$时，$a\in B$，则称$A$是$B$的**子集**，记作$A\subset B$。
- 在比较集合时，人们经常使用**维恩图**。
- 对于$A$、$B$两个集合，**交集**$A\cap B$的定义为：$A\cap B = \{a; a\in A 且 a\in B\}$。
- 对于$A$、$B$两个集合，**并集**$A\cup B$的定义为：$A\cup B = \{a; a\in A 或 a\in B\}$。
- 对于$A$、$B$两个集合，**差集**$A - B$的定义为：$A - B = \{a; a\in A 且 a\notin B\}$。
- 不含任何元素的集合叫作**空集**，记作$\emptyset$。
- 设有集合$S$，当所研究的问题只考虑$S$的子集时，称$S$为**全集**。
- 已知全集$S$，关于$S$的子集$A$有如下关系成立，则称集合$A^{c}$为$A$的**补集**。
- 可能发生的实验结果称为**样本点（$\omega$）**，样本点的总体的集合称为**样本空间（$\Omega$）**。
- 样本空间的子集叫作**事件**。与集合一样，事件也有**并事件**与**交事件**的定义。
- 只由一个样本点组成且不可再分解的事件叫作**基本事件**。含有多个样本点且可以分解为多个基本事件的事件叫作**复合事件**。与空集类似，不含任何样本点的事件叫作**空事件**。
- 当$A\cap B = \emptyset$时，或者当事件之间没有重叠时，称事件$A$和$B$是**互斥事件**。
- **概率的加法公式**是，如果$A$、$B$是互斥事件，则满足：$P(A\cup B) = P(A) + P(B)$。去掉互斥的条件，将概率的加法公式一般化：$P(A\cup B) = P(A) + P(B) - P(A\cap B)$。
- 以发生事件$B$为前提条件，事件$A$发生的概率叫作**条件概率**，记作$P(A|B)$，定义为：$P(A|B) = \frac{P(A\cap B)}{P(B)}$。
- 将条件概率的公式进行变形，可得到：$P(A\cap B) = P(B)\cdot P(A|B)$。该式称为**概率的乘法公式**。
- 当$P(A\cap B) = P(A)\cdot P(B)$成立时，称事件$A$、$B$相独立。变形后就是$P(A|B) = P(A)$。

## 1.9 随机变量与概率分布
- 离散型数据可以通过求概率的总和来得到各种事件的概率，而连续型数据则要通过求概率密度的积分来得到事件的概率。二者的方法是互相对应的。
- 积分就是曲线下方的面积大小。当$n\rightarrow \infty$时，即**当区间分成无穷多个时，面积之和就叫作积分**，表示为$\lim_{n\rightarrow \infty}[\sum_{i=1}^{n}f(x_{i})\times \Delta x] = \int_{a}^{b}f(x)dx$。
- 正态分布的概率密度函数为：$\mathcal{N}(x|\mu , \sigma ^{2}) = \frac{1}{\sqrt{2\pi \sigma ^{2}}}e^{[-\frac{(x - \mu)^{2}}{2\sigma ^2}]}$。
- **独立同分布**即随机变量服从同一分布且相互独立。

# 2 $Python$与$Jupyter Notebook$基础

## 2.1 环境搭建
## 2.2 认识$Jupyter Notebook$
## 2.3 $Python$编程基础
## 2.4 认识$numpy$与$pandas$

# 3 使用$Python$进行数据分析
## 3.1 使用$Python$进行描述统计：单变量
## 3.2 使用$Python$进行描述统计：多变量
## 3.3 基于$matplotlib$、$seaborn$的数据可视化
## 3.4 用$Python$模拟抽样
## 3.5 样本统计量的性质
## 3.6 正态分布及其应用
## 3.7 参数估计
## 3.8 假设检验
## 3.9 均值差的检验
## 3.10 列联表检验
## 3.11 检验结果的解读

# 4 统计模型基础
## 4.1 统计模型
## 4.2 建模方法
## 4.3 数据表示与模型名称
## 4.4 参数估计：最大似然估计
## 4.5 参数估计：最小化损失
## 4.6 预测精度的评估与变量选择

# 5 正态线性模型
## 5.1 含有单个连续型解释变量的模型（一元回归）
## 5.2 方差分析
## 5.3 含有多个解释变量的模型

# 6 广义线性模型
## 6.1 各种概率分布
## 6.2 广义线性模型基础
## 6.3 $logistic$回归
## 6.4 广义线性模型的评估
## 6.5 泊松回归

# 7 统计学与机器学习
## 7.1 机器学习基础
## 7.2 正则化、$Ridge$回归与$Lasso$回归
## 7.3 $Python$中的$Ridge$回归与$Lasso$回归
## 7.4 线性模型与神经网络
## 7.5 扩展内容